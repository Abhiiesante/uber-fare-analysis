{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56642bb9-b10a-49b7-843c-2e326e16d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('uber_rides_data.xlsx - sample_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d777c15-4e4c-418b-915d-b8e3dd862af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fe2bd8-7a55-4deb-92cd-74081583fef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ride_id            200000 non-null  int64  \n",
      " 1   fare_amount        200000 non-null  float64\n",
      " 2   pickup_datetime    200000 non-null  object \n",
      " 3   pickup_longitude   200000 non-null  float64\n",
      " 4   pickup_latitude    200000 non-null  float64\n",
      " 5   dropoff_longitude  199999 non-null  float64\n",
      " 6   dropoff_latitude   199999 non-null  float64\n",
      " 7   passenger_count    200000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd24a607-5386-4b24-a5a3-f64e9abf8cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "missing_values_dropoff_longitude = data['dropoff_longitude'].isnull().sum()\n",
    "print(missing_values_dropoff_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9ed0b2-337a-4092-86f5-4e87d4d3765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e3ed54-7fa0-4794-a635-0ec6f6a82f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.359891549457748\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = data.dropna()\n",
    "average_fare_amount = data_cleaned['fare_amount'].mean()\n",
    "print(average_fare_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a908f157-b09b-4079-84a0-3df444609fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1209923961833708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jella\\AppData\\Local\\Temp\\ipykernel_9384\\905582340.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['haversine_distance'] = data_cleaned.apply(lambda row: haversine_distance(row['pickup_latitude'], row['pickup_longitude'], row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "  R = 6371  \n",
    "\n",
    "  lat1_rad = np.radians(lat1)\n",
    "  lon1_rad = np.radians(lon1)\n",
    "  lat2_rad = np.radians(lat2)\n",
    "  lon2_rad = np.radians(lon2)\n",
    "\n",
    "  dlon = lon2_rad - lon1_rad\n",
    "  dlat = lat2_rad - lat1_rad\n",
    "\n",
    "  a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "  c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "  distance = R * c\n",
    "  return distance\n",
    "\n",
    "data_cleaned['haversine_distance'] = data_cleaned.apply(lambda row: haversine_distance(row['pickup_latitude'], row['pickup_longitude'], row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n",
    "\n",
    "median_haversine_distance = data_cleaned['haversine_distance'].median()\n",
    "print(median_haversine_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd7fd54-b4c6-42df-b4d4-d0cdca2fba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16409.239135313168\n"
     ]
    }
   ],
   "source": [
    "max_haversine_distance = data_cleaned['haversine_distance'].max()\n",
    "print(max_haversine_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21556b9-cd70-4d9c-8db9-2142b7a5db9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632\n"
     ]
    }
   ],
   "source": [
    "zero_distance_rides = data_cleaned[data_cleaned['haversine_distance'] == 0.0]\n",
    "number_of_zero_distance_rides = len(zero_distance_rides)\n",
    "print(number_of_zero_distance_rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4e0eae-f7f8-4527-a5c9-15f20c12ce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.585317826704546\n"
     ]
    }
   ],
   "source": [
    "mean_fare_amount_zero_distance = zero_distance_rides['fare_amount'].mean()\n",
    "print(mean_fare_amount_zero_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2248e9-2ded-4ff9-863e-a2f32ea2c9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.0\n"
     ]
    }
   ],
   "source": [
    "max_fare_amount = data_cleaned['fare_amount'].max()\n",
    "print(max_fare_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cdf5b31-e1d1-4995-b3ee-87e782378c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007899213191009994\n"
     ]
    }
   ],
   "source": [
    "costliest_ride = data_cleaned[data_cleaned['fare_amount'] == data_cleaned['fare_amount'].max()]\n",
    "haversine_distance_costliest_ride = costliest_ride['haversine_distance'].values[0]\n",
    "print(haversine_distance_costliest_ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038c05ae-2e2d-474d-a2e1-6d429676f857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29968\n"
     ]
    }
   ],
   "source": [
    "rides_2014 = data_cleaned[data_cleaned['pickup_datetime'].dt.year == 2014]\n",
    "number_of_rides_2014 = len(rides_2014)\n",
    "print(number_of_rides_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0addf5ff-14c6-4b04-bd18-bdb0f2aa313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7687\n"
     ]
    }
   ],
   "source": [
    "rides_first_quarter_2014 = data_cleaned[(data_cleaned['pickup_datetime'].dt.year == 2014) & (data_cleaned['pickup_datetime'].dt.quarter == 1)]\n",
    "number_of_rides_first_quarter_2014 = len(rides_first_quarter_2014)\n",
    "print(number_of_rides_first_quarter_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf887d9-f15c-4319-8c72-903561edb8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday\n"
     ]
    }
   ],
   "source": [
    "rides_september_2010 = data_cleaned[(data_cleaned['pickup_datetime'].dt.year == 2010) & (data_cleaned['pickup_datetime'].dt.month == 9)]\n",
    "day_of_week_counts = rides_september_2010['pickup_datetime'].dt.day_name().value_counts()\n",
    "max_rides_day = day_of_week_counts.idxmax()\n",
    "print(max_rides_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659b236-c8da-40d5-b303-4d780e1a5878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jella\\AppData\\Local\\Temp\\ipykernel_9384\\3166297761.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['ride_week_day'] = data_cleaned['pickup_datetime'].dt.dayofweek\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data_cleaned['ride_week_day'] = data_cleaned['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "X = data_cleaned[['passenger_count', 'haversine_distance', 'ride_week_day']]\n",
    "y = data_cleaned['fare_amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "decision_tree_reg = DecisionTreeRegressor()\n",
    "random_forest_reg = RandomForestRegressor()\n",
    "\n",
    "linear_reg.fit(X_train, y_train)\n",
    "decision_tree_reg.fit(X_train, y_train)\n",
    "random_forest_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_linear = linear_reg.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree_reg.predict(X_test)\n",
    "y_pred_random_forest = random_forest_reg.predict(X_test)\n",
    "\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "r2_decision_tree = r2_score(y_test, y_pred_decision_tree)\n",
    "r2_random_forest = r2_score(y_test, y_pred_random_forest)\n",
    "\n",
    "print(f\"Linear Regression R-squared: {r2_linear}\")\n",
    "print(f\"Decision Tree Regression R-squared: {r2_decision_tree}\")\n",
    "print(f\"Random Forest Regression R-squared: {r2_random_forest}\")\n",
    "\n",
    "r2_scores = {\n",
    "    'Linear Regression': r2_linear,\n",
    "    'Decision Tree Regression': r2_decision_tree,\n",
    "    'Random Forest Regression': r2_random_forest\n",
    "}\n",
    "\n",
    "algorithm_with_least_r2 = min(r2_scores, key=r2_scores.get)\n",
    "print(f\"\\nThe algorithm with the least R-squared value is: {algorithm_with_least_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577ee80-b8d0-4228-833c-a8ea85938c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
